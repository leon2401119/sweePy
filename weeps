#!/usr/bin/env python3

import threading
import time
import subprocess
from multiprocessing import cpu_count
import numpy as np
from utils import *
import os, signal
import logging
from scheduler import *
import yaml
import copy
import re

with open('weeps.yaml', 'r') as f:
    configs = yaml.safe_load(f)

REPEAT = configs['tunnables']['repeat']
SLEEP_TIME = configs['tunnables']['sleep_time']
STOP_AFTER = configs['tunnables']['stop_after']
ROOT_DIR = configs['paths']['root_dir']
LOG_LVL = configs['miscs']['log_level'] * 10

logging.basicConfig(filename='weeps.log', filemode='w', format='[%(levelname)s] %(asctime)s -- %(message)s', datefmt='%H:%M:%S', level=LOG_LVL)


def prefill_cmd(GAname,**kwargs):
    GA_spec = configs['GAspecs'][GAname]

    argv = GA_spec["io"]["argv"]
    tokens = re.findall('\w+|\[\w+\]|.',argv)

    for idx, token in enumerate(tokens):
        if token == 'pop':               # reserved
            continue

        if re.match('\w+',token):        # required arg
            required = True
        elif re.match('\[\w+\]',token):  # optional arg
            token = token[1:-1]          # strip the [ and ]
            required = False
        else:                            # any other things, generally including seperators like spaces or tabs
            continue

        ## Sequentially search for value replacement, priority from H to L is kwargs -> mappings -> basics -> fixed fields

        # 1. prefill kwarg
        try:
            target = kwargs[token]
            tokens[idx] = str(target)
            logging.info(f'{GAname} argv substitution : "{token}" -> "{target}"  (kwargs)')
            continue
        except Exception as e:
            logging.debug(f'No match for "{token}" in kwargs')

        # 2. prefill mapping
        mapped = False
        for mapping in GA_spec['io']['mappings']:
            src = mapping['to']
            if src == token:
                try:
                    target = configs['basics'][mapping['from']]
                    tokens[idx] = str(mapping['map'][target])
                    logging.info(f'{GAname} argv substitution : "{token}" -> "{target}"  (mappings)')
                    mapped = True
                    break
                except Exception as e:
                    logging.error(f'Found "{src}" to replace with "{target}", but the value of "{target}" is not specified in the basics secion')
                    exit()

        if mapped:
            continue
        else:
            logging.debug(f'No match for "{token}" in mappings')

        # 3. prefill basics
        try:
            target = configs['basics'][token]
            tokens[idx] = str(target)
            logging.info(f'{GAname} argv substitution : "{token}" -> "{target}"  (basics)')
            continue
        except Exception as e:
            logging.debug(f'No match for "{token}" in basics')

        # 4. prefill fixed fileds
        try:
            target = GA_spec['io']['fixed_fields'][token]
            tokens[idx] = str(target)
            logging.info(f'{GAname} argv substitution : "{token}" -> "{target}"  (fixed fields)')
            continue
        except Exception as e:
            logging.debug(f'No match for "{token}" in fixed fields')

        
        if required:  # token is a required arg and no match was found
            logging.error(f'No match for "{token}", which is required in the argv of {GAname}')
            exit()

        else:         # token is an optional keyword and is not specified anywhere
            logging.warning(f'No match for "{token}", since it is optional it will be discarded from argv')
            tokens[idx] = ''   # clear it here
   

    return f'./{GA_spec["bin"]} {"".join(tokens)}'


def prefill_env(GAname,**kwargs):
    GA_spec = configs['GAspecs'][GAname]

    raw_env = copy.deepcopy(GA_spec['io']['envs']) # pitfall: shallow copy modifies the contents of configs

    for key, val in raw_env.items():
        # prefill kwargs
        if val in kwargs.keys():
            raw_env[key] = str(kwargs[val])

    return raw_env


def finalize_cmd(cmd, pop):
    if 'pop' not in cmd:
        logging.error(f'Cannot substitute pop for "{cmd}"')
        exit()

    return cmd.replace('pop',str(pop))


def weep(fffff, ell, inst_num, sch, GAname):
    assert type(sch) is Scheduler, 'weep procedure is not assigned a proper scheduler'

    raw_cmd = prefill_cmd(GAname, instance = inst_num)  # will need to fill in popsize later
    cwd = configs['GAspecs'][GAname]['path']
    env = prefill_env(GAname, instance = inst_num)

    for mapping in configs['GAspecs'][GAname]['io']['mappings']:
        if mapping['from'] == 'fffff':
            dict_fffff_to_problemid = mapping['map']
    problem_id = dict_fffff_to_problemid[fffff]

    data = {}                    # pop,result pairs
    job_arr = []                 # list of (pop,jid) tuples
    wLock = threading.Lock()     # lock for critical sections among threads (particularly in phase 2)

    best_nfe = np.inf
    best_pop = None
    solved = False


    def trial_population(pop): # FIXME : ensure thread-safety
        nonlocal data
        nonlocal best_nfe
        nonlocal best_pop

        results = []
        for _ in range(REPEAT):
            cmd = finalize_cmd(raw_cmd,pop)
            jid = sch.queue(inst_num, cmd, cwd, env)
            out = sch.join(jid, format_DSMGA2_output)

            # FIXME: failed GA run should be included into results as well
            if out[3]: # fail
                break
            else:
                results.append(out)

        if len(results):
            data[pop] = [np.mean(l) for l in list(zip(*results))]
        
        # CRITICAL : possible race condition
        wLock.acquire()
        if len(results) == 10 and data[pop][1] < best_nfe:
            best_nfe = data[pop][1]
            best_pop = pop
        wLock.release()


        if len(results) < 10:
            logging.warning(f'{GAname} inst={inst_num} pop={pop} failed on attempt {len(results)}')
        else:
            logging.info(f'{GAname} inst={inst_num} pop={pop} successful')

        return len(results) == 10

    
    ### phase 1 : stop after STOP_AFTER consecutive nfe increase or the current nfe reaches 2x the best nfe
    def phase1_impl(init_pop):
        nonlocal solved

        current_pop = init_pop

        # TODO : first STOP_AFTER trials can be executed parallely to further decr turnaround time
        while True:
            s = trial_population(current_pop)
            solved = solved or s
       
            ''' break condition 1 : consider solves only '''
            if s and data[current_pop][1] > 2 * best_nfe:
                break

            ''' break condition 1 : consider all '''
            #if data[current_pop][1] > 2 * best_nfe:
            #    break

            ''' check moving average '''
            if s and K_incr_in_mv_avg(data,STOP_AFTER):
                break

            current_pop += 30 # if loop continues


    ### phase 2 : select successful pop with lowest nfe and search its neighborhood
    def phase2_impl(range_obj):

        threads = []
        for pop in range_obj:
            if pop == best_pop: # skip recalculation
                continue
            elif pop <= 0:  # disallow negative population sizes
                continue

            # create & start threads
            thread = threading.Thread(target = trial_population, args=(pop,))
            thread.start()
            threads.append(thread)

        for thread in threads: # wait for all threads to finish
            thread.join()


    phase1_impl(10)
    phase2_impl(range(best_pop-25,best_pop+26,5))
    phase2_impl(range(best_pop-4,best_pop+5,1))


    ### done : print and write out the results

    if inst_num < 0:
        print(f'[{GAname}] {best_pop} {best_nfe}')
    else:
        print(f'[{GAname}] {inst_num} {best_pop} {best_nfe}')

    # FIXME : ./DSMGA2 does not currently record revive count, which should also be monitored be dumped into txt
    if inst_num is not None:
        with open(os.path.join(ROOT_DIR,GAname,f'{problem_id}_{ell}_{inst_num}.txt'),'w') as f:
            for pop in sorted(data.keys()):
                gen,nfe,lsnfe,failnum = data[pop] # failnum is always 0
                f.write(f'{pop}\t{gen}\t{nfe}\t{lsnfe}\t{failnum}\n')

    return best_pop, data[best_pop][0], data[best_pop][1]


def weeps():
    sch = Scheduler()

    threads_dic = {}
    results_dic = {}

    fffff = configs['basics']['fffff']
    ell = configs['basics']['ell']

    for GAname in configs['GAs']:
        # retrieve metadata for GA
        try:
            GAspec = configs['GAspecs'][GAname]
        except Exception as e:
            print(f'No corresponding configuration for GA named {GAname} in the yaml GAspecs')
            exit()

        # validty check
        bin_path = os.path.join(GAspec['path'], GAspec['bin'])
        out_path = os.path.join(ROOT_DIR, GAname)
        os.makedirs(out_path,exist_ok=True) # create folder if non-existant

        assert os.path.exists(bin_path), f'Binary cannot be located at the provided path "{bin_path}"'
        
        if fffff not in configs['Fspecs'].keys():
            print(f'No corresponding configuration for problem named {fffff} in the yaml Fspecs')
            exit()
        
        if 'feasible_ell' in configs['Fspecs'][fffff].keys():
            ell_feasibility_check_func = eval(configs['Fspecs'][fffff]['feasible_ell'])
            if not ell_feasibility_check_func(ell):
                print(f'Infeasible ell for {fffff}')
                exit()
        else:
            logging.warning(f'No ell feasibility checking provided for {fffff}, skipping...')

        if 'instances' in configs['Fspecs'][fffff].keys():
            taskiter = eval(configs['Fspecs'][fffff]['instances'])
            hasInstance = True
        else:
            taskiter = range(10)
            hasInstance = False
       
        # schedule all tasks with multithreading
        threads_dic[GAname] = []
        results_dic[GAname] = []
        
        for i in taskiter:
            thread = threading.Thread(target = lambda l,tup : l.append(weep(*tup)), args = (results_dic[GAname],(fffff,ell,i if hasInstance else -1*i-1,sch,GAname)) )
            thread.start()
            threads_dic[GAname].append(thread)
        print(f'[{GAname}] Starting {fffff} ({ell})')


    while len(threads_dic.keys()):  # main scheduler loop
        global_threads_remain = False
        for GAname in list(threads_dic.keys())[:]:
            threads_remain = False
            for thread in threads_dic[GAname][:]:
                if not thread.is_alive():
                    thread.join()
                    threads_dic[GAname].remove(thread)
                else:
                    threads_remain = True
                    global_threads_remain = True

            if not threads_remain: # sweep for a GA is done
                threads_dic.pop(GAname)
                sweep_results = [(np.mean(l),np.std(l)) for l in zip(*results_dic[GAname])]
                if not len(sweep_results):
                    logging.critical(f'[{GAname}] thread terminated abnormally')
                    continue

                for mapping in configs['GAspecs'][GAname]['io']['mappings']:
                    if mapping['from'] == 'fffff':
                        dict_fffff_to_problemid = mapping['map']
                problem_id = dict_fffff_to_problemid[fffff]

                with open(os.path.join(ROOT_DIR,GAname,f'{problem_id}_{ell}.txt'),'w') as f:
                    f.write(f'{sweep_results[0][0]}\t{sweep_results[1][0]}\t{sweep_results[2][0]}\t{sweep_results[2][1]}')

                print(f'[{GAname}] Summary --- Pop: {sweep_results[0][0]}, Gen: {sweep_results[1][0]}, NFE: {sweep_results[2]}')

        if global_threads_remain:
            sch.schedule()
            #time.sleep(1) # sleep for some time
        else:
            break


if __name__ == '__main__':
    weeps()
