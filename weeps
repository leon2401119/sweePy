#!/usr/bin/env python3

from src.utils import *
from src.io import *
from src.scheduler import *

import threading
import time
import numpy as np
import os, signal
import logging
import yaml
import functools
import csv

with open('weeps.yaml', 'r') as f:
    configs = yaml.safe_load(f)

ROOT_DIR = configs['paths']['root_dir']

logging.basicConfig(
        filename='weeps.log', filemode='w',
        format='[%(levelname)s] %(asctime)s -- %(message)s',
        datefmt='%H:%M:%S',
        level=configs['miscs']['log_level'] * 10
        )


def weep(fffff, ell, inst_num, sch, GAname):
    assert type(sch) is Scheduler, 'weep procedure is not assigned a proper scheduler'

    raw_cmd = prefill_cmd(configs, GAname, instance = inst_num)  # will need to fill in popsize later
    cwd = configs['GAspecs'][GAname]['path']
    env = prefill_env(configs, GAname, instance = inst_num)

    for mapping in configs['GAspecs'][GAname]['io']['mappings']:
        if mapping['from'] == 'fffff':
            dict_fffff_to_problemid = mapping['map']
    problem_id = dict_fffff_to_problemid[fffff]

    data = {}                    # pop,result pairs
    job_arr = []                 # list of (pop,jid) tuples
    wLock = threading.Lock()     # lock for critical sections among threads (particularly in phase 2)

    best_nfe = np.inf
    best_pop = None
    solved = False


    def trial_population(pop): # FIXME : ensure thread-safety
        nonlocal data
        nonlocal best_nfe
        nonlocal best_pop

        #results = []
        out_dicts = []
        reps = configs['tunnables']['repeat']

        for _ in range(reps):
            cmd = finalize_cmd(raw_cmd,pop)
            jid = sch.queue(inst_num, cmd, cwd, env)
            out_dict = sch.join(jid, functools.partial(parse_output, configs, GAname))

            # FIXME: failed GA run should be included into results as well
            if not out_dict: # fail
                break
            else:
                out_dicts.append(out_dict)
        
        if len(out_dicts):
            data[pop] = {key: np.mean([out_dict[key] for out_dict in out_dicts]) for key in out_dicts[0].keys()}
            data[pop]['successes'] = len(out_dicts)

        # CRITICAL : possible race condition
        wLock.acquire()
        if len(out_dicts) == reps and data[pop]['nfe'] < best_nfe:
            best_nfe = data[pop]['nfe']
            best_pop = pop
        wLock.release()


        if len(out_dicts) < reps:
            logging.info(f'{GAname} inst={inst_num} pop={pop} failed on attempt {len(out_dicts)}')
        else:
            logging.info(f'{GAname} inst={inst_num} pop={pop} successful')

        return len(out_dicts) == reps

    
    ### phase 1 : stop after STOP_AFTER consecutive nfe increase or the current nfe reaches 2x the best nfe
    def phase1_impl(init_pop):
        nonlocal solved

        current_pop = init_pop

        # TODO : first STOP_AFTER trials can be executed parallely to further decr turnaround time
        while True:
            s = trial_population(current_pop)
            solved = solved or s
       
            ''' break condition 1 : consider solves only '''
            if s and data[current_pop]['nfe'] > 2 * best_nfe:
                break

            ''' break condition 1 : consider all '''
            #if data[current_pop]['nfe'] > 2 * best_nfe:
            #    break

            ''' check moving average '''
            if s and K_incr_in_mv_avg(data, configs['tunnables']['stop_after']):
                break

            current_pop += 30 # if loop continues


    ### phase 2 : select successful pop with lowest nfe and search its neighborhood
    def phase2_impl(range_obj):

        threads = []
        for pop in range_obj:
            if pop == best_pop: # skip recalculation
                continue
            elif pop <= 0:  # disallow negative population sizes
                continue

            # create & start threads
            thread = threading.Thread(target = trial_population, args=(pop,))
            thread.start()
            threads.append(thread)

        for thread in threads: # wait for all threads to finish
            thread.join()


    phase1_impl(10)
    phase2_impl(range(best_pop-25,best_pop+26,5))
    phase2_impl(range(best_pop-4,best_pop+5,1))


    ### done : print and write out the results

    if inst_num < 0:
        print(f'[{GAname}] {best_pop} {best_nfe}')
    else:
        print(f'[{GAname}] {inst_num} {best_pop} {best_nfe}')

    # FIXME : ./DSMGA2 does not currently record revive count, which should also be monitored be dumped into txt
    if inst_num is not None:
        with open(os.path.join(ROOT_DIR,GAname,f'{problem_id}_{ell}_{inst_num}.csv'),'w') as f:
            column_names = ['pop'] + list(data[best_pop].keys())

            writer = csv.writer(f, delimiter='\t')
            writer.writerow(column_names)

            for pop in sorted(data.keys()):
                writer.writerow([pop] + [data[pop][key] for key in data[pop].keys()])


    return best_pop, data


def weeps():
    sch = Scheduler()

    # job_ctxts is a list of job_ctxt, which stores the usual configurations in the 'basics' section
    job_ctxts = configs['basics'] if type(configs['basics']) is list else [configs['basics']]

    for job_ctxt in job_ctxts:
        configs['basics'] = job_ctxt

        threads_dic = {}
        results_dic = {}

        fffff = configs['basics']['fffff']
        ell = configs['basics']['ell']

        for GAname in configs['GAs']:
            # retrieve metadata for GA
            try:
                GAspec = configs['GAspecs'][GAname]
            except Exception as e:
                print(f'No corresponding configuration for GA named {GAname} in the yaml GAspecs')
                exit()

            # validty check
            bin_path = os.path.join(GAspec['path'], GAspec['bin'])
            out_path = os.path.join(ROOT_DIR, GAname)
            os.makedirs(out_path,exist_ok=True) # create folder if non-existant

            assert os.path.exists(bin_path), f'Binary cannot be located at the provided path "{bin_path}"'
        
            if fffff not in configs['Fspecs'].keys():
                print(f'No corresponding configuration for problem named {fffff} in the yaml Fspecs')
                exit()
        
            if 'feasible_ell' in configs['Fspecs'][fffff].keys():
                ell_feasibility_check_func = eval(configs['Fspecs'][fffff]['feasible_ell'])
                if not ell_feasibility_check_func(ell):
                    print(f'Infeasible ell for {fffff}')
                    exit()
            else:
                logging.warning(f'No ell feasibility checking provided for {fffff}, skipping...')

            if 'instances' in configs['Fspecs'][fffff].keys():
                taskiter = eval(configs['Fspecs'][fffff]['instances'])
                hasInstance = True
            else:
                taskiter = range(10)
                hasInstance = False
       
            # schedule all tasks with multithreading
            threads_dic[GAname] = []
            results_dic[GAname] = []
        
            for i in taskiter:
                # each thread calls weep(fffff,ell,...) and append the result to results_dic[GAname]
                # and the thread itself will be put into threads_dic[GAname] for thread management
                thread = threading.Thread(
                        target = lambda l,tup : l.append(weep(*tup)), 
                        args = (results_dic[GAname], (fffff,ell,i if hasInstance else -1*i-1, sch, GAname))
                        )
                thread.start()
                threads_dic[GAname].append(thread)

            print(f'[{GAname}] Starting {fffff} ({ell})')


        # the main scheduler loop which
        #   1. check status of all scheduled threads
        #   2. collect results from finished threads
        #   3. invoke scheduler if unfinished threads remain

        while len(threads_dic.keys()):
            global_threads_remain = False
            for GAname in list(threads_dic.keys())[:]: # check each GA one-by-one
                threads_remain = False
                for thread in threads_dic[GAname][:]:
                    if not thread.is_alive():
                        thread.join()
                        threads_dic[GAname].remove(thread)
                    else:
                        threads_remain = True
                        global_threads_remain = True

                if not threads_remain: # sweep for a GA is done
                    threads_dic.pop(GAname)
                
                    if not len(results_dic[GAname]):
                        logging.critical(f'[{GAname}] thread terminated abnormally')
                        continue

                    # results_dic[GAname] is a list of dictionaries, each representing the sweep result from an instance
                    # aggregating all instances, we calculate mean/std for each key specified by GA's stdout
                    keys = [key for key in results_dic[GAname][0][1][results_dic[GAname][0][0]]]
                    sweep_results = {
                            key: [dic[bestpop][key] for bestpop,dic in results_dic[GAname]] for key in keys
                            }
                    for key in sweep_results.keys():    
                        sweep_results[key] = (np.mean(sweep_results[key]),np.std(sweep_results[key]))


                    for mapping in configs['GAspecs'][GAname]['io']['mappings']:
                        if mapping['from'] == 'fffff':
                            dict_fffff_to_problemid = mapping['map']
                    problem_id = dict_fffff_to_problemid[fffff]

                    # write the mean/std into csv file
                    with open(os.path.join(ROOT_DIR,GAname,f'{problem_id}_{ell}.csv'),'w') as f:
                        column_names = list(sweep_results.keys())

                        writer = csv.writer(f, delimiter='\t')
                        writer.writerow(column_names)
                        writer.writerow([sweep_results[key][0] for key in sweep_results.keys()])  # mean
                        writer.writerow([sweep_results[key][1] for key in sweep_results.keys()])  # std

                    nfe_tup = sweep_results['nfe']
                    print(f'[{GAname}] Summary --- NFE: {nfe_tup}')

            # unfinished sweep remain
            if global_threads_remain:
                sch.schedule()
                #time.sleep(configs['tunnables']['sleep_time']) # sleep for some time
            else:
                break


if __name__ == '__main__':
    weeps()
